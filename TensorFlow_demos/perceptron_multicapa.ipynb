{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "UTILIDADES\n",
    "'''\n",
    "\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_data(data_type, noise=0.2):\n",
    "    \"\"\"\n",
    "    Generate a binary dataset with distribution data_type\n",
    "\n",
    "    Arguments:\n",
    "    data_type -- distribution of dataset {moons,circles,blobs}\n",
    "\n",
    "    Returns:\n",
    "    X -- features\n",
    "    Y -- labels\n",
    "    \"\"\" \n",
    "    np.random.seed(0)\n",
    "    if data_type == 'moons':\n",
    "        X, Y = datasets.make_moons(200, noise=noise)\n",
    "    elif data_type == 'circles':\n",
    "        X, Y = sklearn.datasets.make_circles(200, noise=noise)\n",
    "    elif data_type == 'blobs':\n",
    "        X, Y = sklearn.datasets.make_blobs(centers=2, cluster_std=noise)\n",
    "    return X, Y\n",
    "\n",
    "def linear_activation(W, b, X):\n",
    "    z = np.dot(W,X) + b\n",
    "    \n",
    "    return z\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1. / (1. + np.exp(-z))\n",
    "\n",
    "def predict_multilayer(parameters,X):\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    Z1 = linear_activation(W1,b1,X)\n",
    "    A1 = sigmoid(Z1)\n",
    "    \n",
    "    Z2 = linear_activation(W2,b2,A1)\n",
    "    A2 = sigmoid(Z2)\n",
    "\n",
    "    return np.round(A2)\n",
    "\n",
    "def visualize_lr(parameters, X, Y):\n",
    "    X = X.T\n",
    "    \n",
    "    # Set min and max values and give it some padding\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole gid\n",
    "    #Z = pred_func(W,b,np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = predict_multilayer(parameters, np.c_[xx.ravel(), yy.ravel()].T)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    \n",
    "    color= ['blue' if y == 1 else 'red' for y in np.squeeze(Y)]\n",
    "    plt.scatter(X[:,0], X[:,1], color=color)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## 1. Cargue del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Dataset de ejemplo para clasificacion binaria\n",
    "'''\n",
    "import sklearn\n",
    "from sklearn.datasets import make_blobs, make_moons\n",
    "\n",
    "dataset = generate_data('circles')\n",
    "x = dataset[0]\n",
    "y = dataset[1]\n",
    "\n",
    "nx,m = x.T.shape\n",
    "\n",
    "colors = ['red' if label == 1 else 'blue' for label in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(x[:,0], x[:,1], color=colors)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#x = x.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## 2. MLP: Implementacion explicita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def d_sigmoid(z):\n",
    "    return tf.nn.sigmoid(z)*(1.-tf.nn.sigmoid(z))\n",
    "\n",
    "def loss(y, a):\n",
    "    return -(y * tf.log(a) + (1.-y) * tf.log(1.-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "learning_rate = 0.6\n",
    "\n",
    "#dataset en forma de tensores\n",
    "X = tf.constant(x.T, dtype=tf.float32, name=\"X\")\n",
    "Y = tf.constant(y, dtype=tf.float32, name=\"Y\")\n",
    "\n",
    "nx = x.shape[1] #numero de caracteristicas de la capa de \n",
    "n_hidden_layer = 10\n",
    "\n",
    "'''\n",
    "parametros de la red\n",
    "'''\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([n_hidden_layer, nx]), name=\"W1\", dtype=tf.float32)\n",
    "b1 = tf.Variable(tf.random_uniform([n_hidden_layer,1]), name=\"b1\", dtype=tf.float32)\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform([1, n_hidden_layer]), name=\"W2\", dtype=tf.float32)\n",
    "b2 = tf.Variable(tf.random_uniform([1, 1]), name=\"b2\", dtype=tf.float32)\n",
    "\n",
    "'''\n",
    "grafo de computo\n",
    "'''\n",
    "\n",
    "'''\n",
    "forward propagation\n",
    "'''\n",
    "Z1 = tf.matmul(W1, X) + b1\n",
    "A1 = tf.nn.sigmoid(Z1)\n",
    "\n",
    "Z2 = tf.matmul(W2, A1) + b2\n",
    "A2 = tf.nn.sigmoid(Z2)\n",
    "\n",
    "'''\n",
    "back propagation\n",
    "'''\n",
    "dZ2 = A2 - Y\n",
    "dW2 = tf.matmul(dZ2, tf.transpose(A1)) / m \n",
    "db2 = tf.reduce_sum(dZ2, axis=1, keep_dims=True) / m\n",
    "\n",
    "dZ1 = tf.multiply(tf.matmul(tf.transpose(W2), dZ2), d_sigmoid(Z1))\n",
    "dW1 = tf.matmul(dZ1, tf.transpose(X)) / m\n",
    "db1 = tf.reduce_sum(dZ1, axis=1, keep_dims=True) / m\n",
    "\n",
    "'''\n",
    "update\n",
    "'''\n",
    "training_W1 = tf.assign(W1, W1 - learning_rate*dW1)\n",
    "training_b1 = tf.assign(b1, b1 - learning_rate*db1)\n",
    "training_W2 = tf.assign(W2, W2 - learning_rate*dW2)\n",
    "training_b2 = tf.assign(b2, b2 - learning_rate*db2)\n",
    "'''\n",
    "cost\n",
    "'''\n",
    "J = tf.reduce_mean(loss(y,A2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## 3. Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "n_epochs = 10000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if(epoch % 1000 == 0):\n",
    "            print (\"Epoca \", epoch, \"Error: \", J.eval(), b1.eval().shape)\n",
    "        \n",
    "        sess.run([training_W1, training_b1, training_W2, training_b2])\n",
    "        \n",
    "        best_W1 = W1.eval()\n",
    "        best_b1 = b1.eval()\n",
    "        best_W2 = W2.eval()\n",
    "        best_b2 = b2.eval()\n",
    "\n",
    "    print best_W1, best_b1\n",
    "    print best_W2, best_b2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'W1':best_W1, 'b1':best_b1, 'W2':best_W2, 'b2':best_b2}\n",
    "visualize_lr(parameters, x.T, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## 4. Implementacion utilizando utilidades de TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "learning_rate = 0.6\n",
    "\n",
    "#dataset en forma de tensores\n",
    "X = tf.constant(x.T, dtype=tf.float32, name=\"X\")\n",
    "Y = tf.constant(y, dtype=tf.float32, name=\"Y\")\n",
    "\n",
    "nx = x.shape[1] #numero de caracteristicas de la capa de \n",
    "n_hidden_layer = 10\n",
    "\n",
    "'''\n",
    "parametros de la red\n",
    "'''\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([n_hidden_layer, nx]), name=\"W1\", dtype=tf.float32)\n",
    "b1 = tf.Variable(tf.random_uniform([n_hidden_layer,1]), name=\"b1\", dtype=tf.float32)\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform([1, n_hidden_layer]), name=\"W2\", dtype=tf.float32)\n",
    "b2 = tf.Variable(tf.random_uniform([1, 1]), name=\"b\", dtype=tf.float32)\n",
    "\n",
    "'''\n",
    "grafo de computo\n",
    "'''\n",
    "\n",
    "'''\n",
    "forward propagation\n",
    "'''\n",
    "Z1 = tf.matmul(W1, X) + b1\n",
    "A1 = tf.nn.sigmoid(Z1)\n",
    "\n",
    "Z2 = tf.matmul(W2, A1) + b2\n",
    "A2 = tf.nn.sigmoid(Z2)\n",
    "\n",
    "'''\n",
    "error\n",
    "'''\n",
    "loss = -(y * tf.log(A2) + (1.-y) * tf.log(1.-A2))\n",
    "J = tf.reduce_mean(loss)\n",
    "\n",
    "'''\n",
    "optimizacion\n",
    "'''\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "n_epochs = 10000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if(epoch % 1000 == 0):\n",
    "            print (\"Epoca \", epoch, \"Error: \", J.eval())\n",
    "        \n",
    "        sess.run(optimizer)\n",
    "        \n",
    "        best_W1 = W1.eval()\n",
    "        best_b1 = b1.eval()\n",
    "        best_W2 = W2.eval()\n",
    "        best_b2 = b2.eval()\n",
    "\n",
    "    print best_W1, best_b1\n",
    "    print best_W2, best_b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'W1':best_W1, 'b1':best_b1, 'W2':best_W2, 'b2':best_b2}\n",
    "visualize_lr(parameters, x.T, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## Trabajemos:\n",
    "Agregue una nueva capa al perceptron multicapa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
