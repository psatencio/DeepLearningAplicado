{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "m,n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Compute Graph\n",
    "'''\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.74651413e+01]\n",
      " [  4.35734153e-01]\n",
      " [  9.33829229e-03]\n",
      " [ -1.06622010e-01]\n",
      " [  6.44106984e-01]\n",
      " [ -4.25131839e-06]\n",
      " [ -3.77322501e-03]\n",
      " [ -4.26648885e-01]\n",
      " [ -4.40514028e-01]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "\n",
    "print theta_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch', 0, 'MSE =', 9.1615419)\n",
      "('Epoch', 100, 'MSE =', 9.1615419)\n",
      "('Epoch', 200, 'MSE =', 9.161541)\n",
      "('Epoch', 300, 'MSE =', 9.1615419)\n",
      "('Epoch', 400, 'MSE =', 9.1615419)\n",
      "('Epoch', 500, 'MSE =', 9.1615419)\n",
      "('Epoch', 600, 'MSE =', 9.1615419)\n",
      "('Epoch', 700, 'MSE =', 9.1615419)\n",
      "('Epoch', 800, 'MSE =', 9.1615419)\n",
      "('Epoch', 900, 'MSE =', 9.161541)\n",
      "[[-0.1673944 ]\n",
      " [-0.46283674]\n",
      " [-0.04063368]\n",
      " [-0.27085733]\n",
      " [ 0.90942287]\n",
      " [ 0.88372922]\n",
      " [ 0.2296679 ]\n",
      " [-0.28315711]\n",
      " [ 0.18720484]]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "'''\n",
    "Explicit Gradient Descent\n",
    "'''\n",
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch', 0, 'MSE=', 10.286603)\n",
      "('Epoch', 100, 'MSE=', 9.9733601)\n",
      "('Epoch', 200, 'MSE=', 9.6803942)\n",
      "('Epoch', 300, 'MSE=', 9.4063177)\n",
      "('Epoch', 400, 'MSE=', 9.1498413)\n",
      "('Epoch', 500, 'MSE=', 8.9097662)\n",
      "('Epoch', 600, 'MSE=', 8.6849785)\n",
      "('Epoch', 700, 'MSE=', 8.4744425)\n",
      "('Epoch', 800, 'MSE=', 8.2771959)\n",
      "('Epoch', 900, 'MSE=', 8.0923433)\n",
      "[[-0.21868253]\n",
      " [-0.18326624]\n",
      " [ 0.81288898]\n",
      " [-0.43025935]\n",
      " [-0.2653321 ]\n",
      " [ 0.40435165]\n",
      " [-0.72610581]\n",
      " [ 0.6070227 ]\n",
      " [ 0.22958989]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Gradient Descent using AutoDiff\n",
    "'''\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "scaler.fit(housing_data_plus_bias)\n",
    "scaled_housing_data_plus_bias = scaler.transform(housing_data_plus_bias)\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "\n",
    "\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = tf.gradients(mse, [theta])[0]\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if(epoch % 100 == 0):\n",
    "            print(\"Epoch\", epoch, \"MSE=\", mse.eval())\n",
    "            sess.run(training_op)\n",
    "        \n",
    "        best_theta = theta.eval()\n",
    "\n",
    "print best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch', 0, 'MSE=', 7.3321881)\n",
      "('Epoch', 100, 'MSE=', 7.2273278)\n",
      "('Epoch', 200, 'MSE=', 7.0397882)\n",
      "('Epoch', 300, 'MSE=', 6.797636)\n",
      "('Epoch', 400, 'MSE=', 6.5301552)\n",
      "('Epoch', 500, 'MSE=', 6.2639127)\n",
      "('Epoch', 600, 'MSE=', 6.0199814)\n",
      "('Epoch', 700, 'MSE=', 5.812418)\n",
      "('Epoch', 800, 'MSE=', 5.6479931)\n",
      "('Epoch', 900, 'MSE=', 5.5269337)\n",
      "[[-0.68307185]\n",
      " [ 0.65614766]\n",
      " [-0.1213624 ]\n",
      " [ 0.28206643]\n",
      " [-0.50254589]\n",
      " [-0.38790596]\n",
      " [ 0.11193584]\n",
      " [ 0.47083807]\n",
      " [ 0.45712954]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Gradient Descent Using Optimizer\n",
    "'''\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "scaler.fit(housing_data_plus_bias)\n",
    "scaled_housing_data_plus_bias = scaler.transform(housing_data_plus_bias)\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "\n",
    "\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if(epoch % 100 == 0):\n",
    "            print(\"Epoch\", epoch, \"MSE=\", mse.eval())\n",
    "            sess.run(training_op)\n",
    "        \n",
    "        best_theta = theta.eval()\n",
    "\n",
    "print best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## Place holders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "B = A + 5\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict={A:[[1,2,3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A:[[4,5,6],[7,8,9]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.  7.  8.]]\n",
      "[[  9.  10.  11.]\n",
      " [ 12.  13.  14.]]\n"
     ]
    }
   ],
   "source": [
    "print B_val_1\n",
    "print B_val_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
